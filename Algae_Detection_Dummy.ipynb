{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsEt4UDQCRrWi9NhCtmxvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krupa-1010/Deep_Learning/blob/main/Algae_Detection_Dummy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "a3bKKenRlyjX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets,transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\",device)"
      ],
      "metadata": {
        "id": "uZd28ONMsdj6",
        "outputId": "d7ffcd06-a32f-4e04-bcfb-7b05fde88a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "Jj-Q6Grms8RS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "test_datset=datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)"
      ],
      "metadata": {
        "id": "ObVJo8x6u3y6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "dn64Tqi91IUa",
        "outputId": "364cd8b9-c28d-4d46-cc84-ef7b56242a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datset"
      ],
      "metadata": {
        "id": "GyT7LOXT1WlQ",
        "outputId": "d0b905c1-c217-40b3-8e58-549d37ae5699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: ./data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "mKz1AD9w1HmF",
        "outputId": "4ced643b-ed7a-40ed-e99c-1ab5457c1af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
              "          [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
              "          [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
              "          ...,\n",
              "          [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
              "          [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
              "          [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
              " \n",
              "         [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
              "          [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
              "          [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
              "          ...,\n",
              "          [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
              "          [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
              "          [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
              " \n",
              "         [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
              "          [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
              "          [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
              "          ...,\n",
              "          [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
              "          [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
              "          [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]]),\n",
              " 6)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True,num_workers=2)\n",
        "test_loader=DataLoader(test_datset,batch_size=64,shuffle=False,num_workers=2)"
      ],
      "metadata": {
        "id": "24FA8W5zwFqh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model\n",
        "class AlgaeCNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv_layers=nn.Sequential(\n",
        "        nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "\n",
        "        nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "      )\n",
        "\n",
        "    self.fc_layer=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(128*4*4,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256,10),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv_layers(x)\n",
        "    x=self.fc_layer(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Ih0jzXdTxglx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=AlgaeCNN().to(device)"
      ],
      "metadata": {
        "id": "hSYpEJKB5LwB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n"
      ],
      "metadata": {
        "id": "ksPnAJ685UjQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "epochs=20\n",
        "train_losses=[]\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "for epoch in range(epochs):\n",
        "  running_loss=0.0\n",
        "  correct=0\n",
        "  total=0\n",
        "\n",
        "  model.train()\n",
        "  for i,(inputs,labels) in enumerate(train_loader):\n",
        "    inputs,labels=inputs.to(device),labels.to(device)\n",
        "    outputs=model(inputs)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    running_loss+=loss.item()\n",
        "\n",
        "    _,predicted=outputs.max(1)\n",
        "    total+=labels.size(0)\n",
        "    correct +=predicted.eq(labels).sum().item()\n",
        "\n",
        "  average_loss=running_loss/len(train_loader)\n",
        "  train_losses.append(average_loss)\n",
        "  tr_accuracy=100*correct /total\n",
        "  train_accuracy.append(tr_accuracy)\n",
        "\n",
        "  print(f\"Epoch {epoch}, Loss: {average_loss:.4f} Train Accuracy ={tr_accuracy:.2f}%\")\n",
        "\n",
        "  #test\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_correct=0\n",
        "    test_total=0\n",
        "    for b,(test_inputs,test_labels) in enumerate(test_loader):\n",
        "      test_inputs,test_labels=test_inputs.to(device),test_labels.to(device)\n",
        "      test_outputs=model(test_inputs)\n",
        "      _,y_predicted=test_outputs.max(1)\n",
        "      test_correct+=y_predicted.eq(test_labels).sum().item()\n",
        "      test_total+=test_labels.size(0)\n",
        "\n",
        "    te_accuracy=100*test_correct/test_total\n",
        "    test_accuracy.append(te_accuracy)\n",
        "\n",
        "    print(f\"Test Accuracy:{te_accuracy:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ei3Fo62s5t8h",
        "outputId": "df82704d-f7ef-49eb-f07c-11d679d09c88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.4947 Train Accuracy =45.91%\n",
            "Test Accuracy:58.82%\n",
            "Epoch 1, Loss: 1.0861 Train Accuracy =61.75%\n",
            "Test Accuracy:64.60%\n",
            "Epoch 2, Loss: 0.9040 Train Accuracy =68.26%\n",
            "Test Accuracy:70.49%\n",
            "Epoch 3, Loss: 0.7880 Train Accuracy =72.23%\n",
            "Test Accuracy:72.00%\n",
            "Epoch 4, Loss: 0.7005 Train Accuracy =75.53%\n",
            "Test Accuracy:72.59%\n",
            "Epoch 5, Loss: 0.6382 Train Accuracy =77.59%\n",
            "Test Accuracy:75.95%\n",
            "Epoch 6, Loss: 0.5796 Train Accuracy =79.65%\n",
            "Test Accuracy:76.34%\n",
            "Epoch 7, Loss: 0.5243 Train Accuracy =81.51%\n",
            "Test Accuracy:76.44%\n",
            "Epoch 8, Loss: 0.4783 Train Accuracy =83.21%\n",
            "Test Accuracy:76.77%\n",
            "Epoch 9, Loss: 0.4370 Train Accuracy =84.49%\n",
            "Test Accuracy:76.93%\n",
            "Epoch 10, Loss: 0.3964 Train Accuracy =86.01%\n",
            "Test Accuracy:76.83%\n",
            "Epoch 11, Loss: 0.3690 Train Accuracy =86.60%\n",
            "Test Accuracy:77.42%\n",
            "Epoch 12, Loss: 0.3404 Train Accuracy =87.70%\n",
            "Test Accuracy:76.81%\n",
            "Epoch 13, Loss: 0.3169 Train Accuracy =88.46%\n",
            "Test Accuracy:76.73%\n",
            "Epoch 14, Loss: 0.2955 Train Accuracy =89.17%\n",
            "Test Accuracy:77.65%\n",
            "Epoch 15, Loss: 0.2765 Train Accuracy =89.80%\n",
            "Test Accuracy:77.53%\n",
            "Epoch 16, Loss: 0.2658 Train Accuracy =90.40%\n",
            "Test Accuracy:77.28%\n",
            "Epoch 17, Loss: 0.2476 Train Accuracy =90.98%\n",
            "Test Accuracy:76.80%\n",
            "Epoch 18, Loss: 0.2401 Train Accuracy =91.20%\n",
            "Test Accuracy:77.47%\n",
            "Epoch 19, Loss: 0.2329 Train Accuracy =91.39%\n",
            "Test Accuracy:77.27%\n"
          ]
        }
      ]
    }
  ]
}